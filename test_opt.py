#!/usr/bin/env python3
# -*- coding: utf-8 -*-


import cv2
import numpy as np
import time
import math
import os
import json
import sys
from audio_player import AudioPlayer
from datetime import datetime
from hud_manager import HUDManager
from motion_detector import MotionDetector

# ---------------------------
# --- –ó–∞–≥–ª—É—à–∫–∏ / –±–µ–∑–ø–µ—á–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏ ---
# ---------------------------
# –Ø–∫—â–æ —É —Ç–µ–±–µ —î —Ä–µ–∞–ª—å–Ω—ñ –º–æ–¥—É–ª—ñ ldtest, hud_manager, hls_player, wifi_hotspot ‚Äî –≤–æ–Ω–∏ –±—É–¥—É—Ç—å —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω—ñ.
# –Ø–∫—â–æ –Ω—ñ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –ø—Ä–æ—Å—Ç—ñ –∑–∞–≥–ª—É—à–∫–∏, —â–æ–± –∫–æ–¥ –º–æ–∂–Ω–∞ –±—É–ª–æ –∑–∞–ø—É—Å—Ç–∏—Ç–∏.
try:
    from PIL import ImageFont, ImageDraw, Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("‚ö†Ô∏è  Pillow –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –£–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –ª—ñ—Ç–µ—Ä–∏ –≤ HUD –Ω–µ –±—É–¥—É—Ç—å –≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏—Å—å.")

try:
    from ldtest import LRF
except Exception:
    class LRF:
        SINGLE = 0
        def __init__(self, port=None, enable_pin=None, mode=None):
            self._on = False
        def power_on(self):
            self._on = True
        def power_off(self):
            self._on = False
        def get_single_measurement(self):
            # –∑–∞–≥–ª—É—à–∫–∞: –≤–∏–ø–∞–¥–∫–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è
            return 123.4

try:
    from wifi_hotspot import WifiHotspotServer
except Exception:
    class WifiHotspotServer:
        def __init__(self, ssid="Pi", password=None, folder="download", port=8000):
            print("WifiHotspotServer: –∑–∞–≥–ª—É—à–∫–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        def start_all(self):
            print("WifiHotspotServer: start_all (–∑–∞–≥–ª—É—à–∫–∞)")

# –°–ø—Ä–æ–±–∞ —ñ–º–ø–æ—Ä—Ç—É HLSVideo (–ø–æ–≤–∏–Ω–µ–Ω –Ω–∞–¥–∞–≤–∞—Ç–∏ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å—Ö–æ–∂–∏–π –Ω–∞ VideoCapture)
HLS_AVAILABLE = True
try:
    from hls_player import HLSVideo
except Exception:
    HLS_AVAILABLE = False
    class HLSVideo:
        def __init__(self, url, fps=30, width=1024, height=600):
            print("HLSVideo: –∑–∞–≥–ª—É—à–∫–∞, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è cv2.VideoCapture")
            # —Å–ø—Ä–æ–±—É—î–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ OpenCV –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö HTTP MJPEG/RTSP/—Ñ–∞–π–ª—ñ–≤
            self.cap = cv2.VideoCapture(url)
            self._fps = fps
            self._width = width
            self._height = height
        def isOpened(self):
            return self.cap.isOpened()
        def read(self):
            return self.cap.read()
        def release(self):
            return self.cap.release()
        def get(self, prop):
            return self.cap.get(prop)
        def set(self, prop, val):
            return self.cap.set(prop, val)

# ---------------------------
# --- –ö–æ–Ω—Ñ—ñ–≥ —Ç–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏ ---
# ---------------------------
FRAME_W, FRAME_H = 1024, 600
ZOOM_STEP = 0.06
ZOOM_MIN, ZOOM_MAX = 1.0, 5.0
CONTINUOUS_AUTO_OFF_MINUTES = 2
RECORD_DIR = "record"
MENU_FILES_PER_PAGE = 15
FPS = 30.0

STREAMS_JSON = "hls_streams.json"

# –Ø–∫—â–æ –Ω–µ–º–∞—î streams.json ‚Äî —Å—Ç–≤–æ—Ä–∏–º–æ –¥–µ—Ñ–æ–ª—Ç–Ω–∏–π
DEFAULT_STREAMS = [
  {
    "name": "Norvegian cam 1",
    "url": "http://109.247.15.178:6001/mjpg/video.mjpg"
  },
  {
    "name": "beach",
    "url": "http://85.196.146.82:3337/mjpg/video.mjpg"}
    ,
  
   { "name": "boats club",
    "url": "http://213.236.250.78/mjpg/video.mjpg"
    },
    {
      "name": "park",
      "url": "http://192.171.163.3/?id=3324&imagePath=/mjpg/video.mjpg&size=1"
      }

]
def ensure_streams_file(filename=STREAMS_JSON):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Ñ–∞–π–ª—É `hls_streams.json` —ñ —Å—Ç–≤–æ—Ä—é—î –π–æ–≥–æ
    –∑—ñ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º, —è–∫—â–æ —Ñ–∞–π–ª –≤—ñ–¥—Å—É—Ç–Ω—ñ–π.
    """
    if not os.path.exists(filename):
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(DEFAULT_STREAMS, f, ensure_ascii=False, indent=2)
        print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ –¥–µ—Ñ–æ–ª—Ç–Ω–∏–π {filename}")

def load_hls_streams(filename=STREAMS_JSON):
    if not os.path.exists(filename):
        ensure_streams_file(filename)
    try:
        with open(filename, "r", encoding="utf-8") as f:
            streams = json.load(f)
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –≤–∞–ª—ñ–¥–Ω—ñ –∑–∞–ø–∏—Å–∏
            valid_streams = [s for s in streams if isinstance(s, dict) and "url" in s and "name" in s]
            streams = valid_streams[:8]  # –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à—ñ 8 —Å—Ç—Ä—ñ–º—ñ–≤
            return streams
    except Exception as e:
        print("–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è streams.json:", e)
        print(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è {filename}:", e)
        return []

# ---------------------------
# --- –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–ø–∞—Ä–∞—Ç—É—Ä–∏ —Ç–∞ —Å—Ç–∞–Ω—ñ–≤ ---
# ---------------------------
hotspot = WifiHotspotServer(ssid="PiLdVideo", password="video1234", folder="download", port=8000)

lrf_sensor = LRF(port='/dev/ttyAMA0', enable_pin=17, mode=LRF.SINGLE)
lrf_sensor.power_on()  # –Ω–∞ —Å—Ç–∞—Ä—Ç—ñ –º–æ–∂–µ–º–æ –≤–∫–ª—é—á–∏—Ç–∏, –∞–±–æ –∫–µ—Ä—É–≤–∞—Ç–∏ –ø—ñ–∑–Ω—ñ—à–µ
lrf_powered = True

# --- –®—Ä–∏—Ñ—Ç–∏ –¥–ª—è HUD ---
FONT_PATH = "/home/laserlab/LD_PROJECT/DejaVuSans.ttf"
if PIL_AVAILABLE and os.path.exists(FONT_PATH):
    FONT_HUD = ImageFont.truetype(FONT_PATH, 16)
    FONT_HUD_LARGE = ImageFont.truetype(FONT_PATH, 22)
    FONT_STREAM_MODE = ImageFont.truetype(FONT_PATH, 24)
    FONT_HLS = ImageFont.truetype(FONT_PATH, 14)
else:
    FONT_HUD = None
    FONT_HUD_LARGE = None
    FONT_STREAM_MODE = None
    FONT_HLS = None
    
# HUD, —Ö–æ—Ç—Å–ø–æ—Ç, LRF
hud = HUDManager(font=FONT_HUD_LARGE)

# ---------------------------
# --- –ü–æ—Ç–æ–∫–∏ —Ç–∞ device_list ---
# ---------------------------
hls_streams = load_hls_streams(STREAMS_JSON)
current_hls_idx = 0  # —ñ–Ω–¥–µ–∫—Å –∞–∫—Ç–∏–≤–Ω–æ–≥–æ HLS-–ø–æ—Ç–æ–∫—É

# –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤: pipeline CSI / /dev/video0 / HLS
device_list = [
    "libcamerasrc ! video/x-raw,format=BGR,width=1024,height=600,framerate=30/1 ! videoconvert ! appsink",
    "/dev/video0"
]
if hls_streams:
    device_list.append(hls_streams[current_hls_idx]["url"])
else:
    device_list.append("")  # placeholder

camera_labels = ["Wide camera", "Thermal camera", "HTTP Stream"]
current_cam_idx = 0

# ---------------------------
# --- –ì–ª–æ–±–∞–ª—å–Ω—ñ —Å—Ç–∞–Ω–∏ UI ---
# ---------------------------
show_crosshair = False
zoom = 1.0
continuous_measure = False
continuous_start_time = None
motion_detection_active = False
enhance_active = False
recording = False
video_writer = None
distance_text = "Distance: N/A"
active_set = "HUD"
menu_page = 0
menu_files = []
continuous_off_msg = ""
button_sets = {}
button_pressed = {}

# –õ—ñ—á–∏–ª—å–Ω–∏–∫ –∫–∞–¥—Ä—ñ–≤ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
frame_count = 0
MOTION_DETECT_FRAME_SKIP = 5 # –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –∫–æ–∂–µ–Ω 5-–π –∫–∞–¥—Ä

# –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä—É—Ö—É
motion_detector = MotionDetector(
    min_contour_area=300,   # –ó–±—ñ–ª—å—à–µ–Ω–æ –∑ 100. –Ü–≥–Ω–æ—Ä—É—î–º–æ –¥—Ä—ñ–±–Ω—ñ –æ–±'—î–∫—Ç–∏.
    scale_factor=0.6,       # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∑–º–µ–Ω—à–µ–Ω–∏–π –∫–∞–¥—Ä –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ.
    var_threshold=700       # –ó–±—ñ–ª—å—à–µ–Ω–æ –∑ 50. –†–æ–±–∏—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä –º–µ–Ω—à —á—É—Ç–ª–∏–≤–∏–º –¥–æ –∑–º—ñ–Ω –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è.
)

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—É–¥—ñ–æ–ø–ª–µ—î—Ä–∞
audio_player = AudioPlayer("/home/laserlab/LD_PROJECT/alarm-clock-beep-1_zjgin-vd.mp3")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—É–¥—ñ–æ–ø–ª–µ—î—Ä–∞
audio_player_ondetect = AudioPlayer("/home/laserlab/LD_PROJECT/audio-editor-output.mp3")

# Video playback
video_playing = False
video_cap = None

# mouse state
mouse_pressed_name = None
mouse_pressed_rect = None
mouse_pressed_set = None

# HLS buttons layout
HLS_BTN_SIZE = 40
HLS_BTN_SPACING = 10
HLS_BTN_X_START = 200
HLS_BTN_Y_START = 10

# Close btn for playback
close_x = close_y = close_w = close_h = 0

# Blink start
blink_start_time = time.time()

# --- –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –∫–∞–º–µ—Ä / HLS ---
def open_camera(index):
    global current_hls_idx
    source = None
    try:
        source = device_list[index]
    except IndexError:
        return None

    if isinstance(source, str):
        # HLS case: third index (2)
        if index == 2 and hls_streams:
            url = hls_streams[current_hls_idx]["url"]
            try:
                cap = HLSVideo(url, fps=FPS, width=FRAME_W, height=FRAME_H)
                # —è–∫—â–æ —É HLSVideo —î isOpened:
                if hasattr(cap, "isOpened"):
                    if not cap.isOpened():
                        print("HLSVideo –Ω–µ –≤—ñ–¥–∫—Ä–∏–≤—Å—è, –ø—Ä–æ–±—É—î–º–æ OpenCV")
                return cap
            except Exception as e:
                print("HLSVideo error:", e)
                # fallback to cv2
                cap = cv2.VideoCapture(url)
                return cap

        # /dev/video* device
        if source.startswith("/dev/"):
            cap = cv2.VideoCapture(source, cv2.CAP_V4L2)
            if not cap.isOpened():
                cap = cv2.VideoCapture(source)
            try:
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_W)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H)
            except Exception:
                pass
            return cap

        # GStreamer pipeline (string with '!')
        if "!" in source:
            cap = cv2.VideoCapture(source, cv2.CAP_GSTREAMER)
            return cap

        # Generic HTTP/RTSP/local file
        cap = cv2.VideoCapture(source)
        return cap
    else:
        # other types
        return None

# –ó–∞–ø—É—Å–∫–∞—î–º–æ —Å—Ç–∞—Ä—Ç–æ–≤—É –∫–∞–º–µ—Ä—É
cap = open_camera(current_cam_idx)
if cap is None or (hasattr(cap, "isOpened") and not cap.isOpened()):
    print("–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –ø–æ—á–∞—Ç–∫–æ–≤—É –∫–∞–º–µ—Ä—É:", device_list[current_cam_idx])
    # —Å–ø—Ä–æ–±—É—î–º–æ /dev/video0
    current_cam_idx = 1
    cap = open_camera(current_cam_idx)
    if cap is None or (hasattr(cap, "isOpened") and not cap.isOpened()):
        print("–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –∫–∞–º–µ—Ä.")
        # –Ω–µ —Ä–æ–±–∏–º–æ exit ‚Äî –¥–∞—î–º–æ —à–∞–Ω—Å –∑–∞–ø—É—Å—Ç–∏—Ç–∏ —ñ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏
        # sys.exit(1)

# --- Enhancement filter ---
def enhance_image(frame):
    alpha, beta = 1.8, 20
    frame_enhanced = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    return cv2.filter2D(frame_enhanced, -1, kernel)

# --- –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –º–∞–ª—é–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é UTF-8 ---
def draw_text_pil(frame, text, pos, font, color=(255, 255, 255)):
    """
    –ú–∞–ª—é—î —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∞–¥—Ä—ñ OpenCV –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Pillow.
    –ü—ñ–¥—Ç—Ä–∏–º—É—î UTF-8 —Å–∏–º–≤–æ–ª–∏.
    """
    if not PIL_AVAILABLE or not font:
        # Fallback –¥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ cv2.putText, —è–∫—â–æ Pillow –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π
        # –∞–±–æ —à—Ä–∏—Ñ—Ç –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ. –ö–∏—Ä–∏–ª–∏—Ü—è –Ω–µ –±—É–¥–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏.
        cv2.putText(frame, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        return frame

    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –∫–∞–¥—Ä OpenCV (BGR) –≤ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è Pillow (RGB)
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)

    # –ú–∞–ª—é—î–º–æ —Ç–µ–∫—Å—Ç
    draw.text(pos, text, font=font, fill=color)

    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –Ω–∞–∑–∞–¥ –≤ –∫–∞–¥—Ä OpenCV
    frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    return frame


# --- Buttons system (HUD/Menu) ---
def create_button_set(name, buttons_dict):
    button_sets[name] = buttons_dict
    for btn in buttons_dict.keys():
        button_pressed[btn] = False

def set_active_button_set(name):
    global active_set
    if name in button_sets:
        active_set = name

create_button_set("HUD", {
    "crosshair": (10, 10, 150, 50, "Crosshair"),
    "zoom_in": (10, 70, 150, 50, "Zoom +"),
    "zoom_out": (10, 130, 150, 50, "Zoom -"),
    "switch_cam": (10, 190, 150, 50, camera_labels[current_cam_idx]),
    "single_measure": (10, 250, 150, 50, "Single Measure"),
    "continuous_measure": (10, 310, 150, 50, "Cont. Measure"),
    "enhance": (10, 370, 150, 50, "Enhance"),
    "record": (10, 430, 150, 50, "Record"),
    "play": (10, 490, 150, 50, "Play"),
    "motion_detect": (10, 550, 150, 50, "Motion Detect")
})

def update_switch_cam_label():
    if "HUD" in button_sets and "switch_cam" in button_sets["HUD"]:
        x, y, w, h, _ = button_sets["HUD"]["switch_cam"]
        button_sets["HUD"]["switch_cam"] = (x, y, w, h, camera_labels[current_cam_idx])

# --- Recording / menu files ---
def start_or_stop_recording():
    global recording, video_writer
    if not os.path.exists(RECORD_DIR):
        os.makedirs(RECORD_DIR)
    if not recording:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(RECORD_DIR, f"rec_{timestamp}.mp4")
        video_writer = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'mp4v'), FPS, (FRAME_W, FRAME_H))
        recording = True
        print("‚ñ∂Ô∏è –ó–∞–ø–∏—Å —Å—Ç–∞—Ä—Ç—É–≤–∞–≤:", filename)
    else:
        recording = False
        if video_writer:
            video_writer.release()
            video_writer = None
        print("‚èπ –ó–∞–ø–∏—Å –∑—É–ø–∏–Ω–µ–Ω–æ")

def update_menu_files():
    global menu_files
    if not os.path.exists(RECORD_DIR):
        os.makedirs(RECORD_DIR)
    menu_files = sorted([f for f in os.listdir(RECORD_DIR) if f.endswith(".mp4")],
                        key=lambda x: os.path.getmtime(os.path.join(RECORD_DIR, x)),
                        reverse=True)

def get_menu_buttons(page):
    buttons = {}
    start_idx = page * MENU_FILES_PER_PAGE
    end_idx = start_idx + MENU_FILES_PER_PAGE
    files_to_show = menu_files[start_idx:end_idx]

    col_w, col_h = 200, 40
    x_positions = [10, 220, 430]
    y_start = 10
    spacing = 10

    for i, fname in enumerate(files_to_show):
        col_idx = i % 3
        row_idx = i // 3
        col = x_positions[col_idx]
        row = y_start + row_idx * (col_h + spacing)
        name_no_ext = os.path.splitext(fname)[0]
        buttons[f"file_{fname}"] = (col, row, col_w, col_h, name_no_ext)

    btn_y = y_start + 5 * (col_h + spacing) + 20
    if (page + 1) * MENU_FILES_PER_PAGE < len(menu_files):
        buttons["next_page"] = (10, btn_y, 150, 40, "Next")
    if page > 0:
        buttons["prev_page"] = (170, btn_y, 150, 40, "Prev")
    buttons["back"] = (340, btn_y, 150, 40, "Back")
    buttons["delete_all"] = (500, btn_y, 180, 40, "Delete All")
    return buttons

def refresh_menu_buttons():
    global button_sets
    update_menu_files()
    button_sets["Menu"] = get_menu_buttons(menu_page)

# --- Video playback ---
def start_video(filename):
    global video_playing, video_cap
    filepath = os.path.join(RECORD_DIR, filename)
    if not os.path.exists(filepath):
        print("–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ:", filepath)
        return
    video_cap = cv2.VideoCapture(filepath)
    if not video_cap.isOpened():
        print("–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –≤—ñ–¥–µ–æ:", filepath)
        return
    video_playing = True

def stop_video():
    global video_playing, video_cap
    if video_cap:
        video_cap.release()
    video_playing = False
    set_active_button_set("Menu")
    refresh_menu_buttons()

# --- Measures / camera switching ---
def do_single_measure():
    global distance_text, lrf_powered
    if not lrf_powered:
        lrf_sensor.power_on()
        lrf_powered = True
        time.sleep(0.3) # –î–∞—î–º–æ —á–∞—Å –Ω–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—é

    result = lrf_sensor.get_single_measurement()
    if result:
        distance_text = f"Distance: {result:.1f} m"
    else:
        distance_text = "Distance: N/A"
    hud.show_message("Single measurement done")

def switch_camera():
    global current_cam_idx, cap, hud
    global current_cam_idx, cap, hud, motion_detection_active

    if motion_detection_active:
        motion_detection_active = False
        hud.show_message("Motion Detection OFF (camera switched)")

    motion_detector.reset() # –°–∫–∏–¥–∞—î–º–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø—Ä–∏ –∑–º—ñ–Ω—ñ –∫–∞–º–µ—Ä–∏
    
    previous_cam_idx = current_cam_idx
    
    try:
        cap.release()
    except Exception:
        pass
    current_cam_idx = (current_cam_idx + 1) % len(device_list)
    cap = open_camera(current_cam_idx)
    if not cap or (hasattr(cap, "isOpened") and not cap.isOpened()):
        cam_name = camera_labels[current_cam_idx]
        hud.show_message(f"Error: {cam_name} not found")
        print(f"–ü–æ–º–∏–ª–∫–∞: –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –∫–∞–º–µ—Ä—É {cam_name}")
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –¥–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –∫–∞–º–µ—Ä–∏
        current_cam_idx = previous_cam_idx
        cap = open_camera(current_cam_idx)
    update_switch_cam_label()


# --- HLS stream switching ---
def switch_hls_stream(index):
    global current_hls_idx, cap, device_list
    global current_hls_idx, cap, device_list, motion_detection_active

    if motion_detection_active:
        motion_detection_active = False
        hud.show_message("Motion Detection OFF (stream switched)")

    if index < 0 or index >= len(hls_streams):
        motion_detector.reset() # –°–∫–∏–¥–∞—î–º–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø—Ä–∏ –∑–º—ñ–Ω—ñ —Å—Ç—Ä—ñ–º—É
        return
    current_hls_idx = index
    # –û–Ω–æ–≤–ª—é—î–º–æ device_list[2] –Ω–∞ –Ω–æ–≤–∏–π URL (–Ω–∞ –≤–∏–ø–∞–¥–æ–∫, —è–∫—â–æ —ñ–Ω—à–∏–º–∏ –º—ñ—Å—Ü—è–º–∏ –∑–≤–µ—Ä—Ç–∞—î–º–æ—Å—å)
    device_list[2] = hls_streams[current_hls_idx]["url"]
    try:
        cap.release()
    except Exception:
        pass
    # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ HLS (—è–∫—â–æ –∑–∞—Ä–∞–∑ –∞–∫—Ç–∏–≤–Ω–∞ HTTP –∫–∞–º–µ—Ä–∞)
    if current_cam_idx == 2:
        cap = open_camera(2)
    print(f"üîÑ –ü–µ—Ä–µ–º–∏–∫–∞–Ω–Ω—è HLS ‚Üí {hls_streams[current_hls_idx]['name']}")

# --- Button callback ---
def menu_button_callback(name):
    global menu_page
    if name.startswith("file_"):
        filename = name[5:]
        start_video(filename)
    elif name == "next_page":
        menu_page += 1
    elif name == "prev_page":
        menu_page -= 1
    elif name == "back":
        set_active_button_set("HUD")
    elif name == "delete_all":
        for f in menu_files:
            os.remove(os.path.join(RECORD_DIR, f))
        menu_page = 0
        update_menu_files()
        refresh_menu_buttons()
        print("üóë –£—Å—ñ —Ñ–∞–π–ª–∏ –≤–∏–¥–∞–ª–µ–Ω–æ")
    refresh_menu_buttons()

def button_callback(name, pressed, current_set):
    global show_crosshair, zoom, recording, enhance_active, continuous_measure, continuous_start_time
    global lrf_powered, distance_text, video_playing, motion_detection_active
    if not pressed:
        return

    if current_set == "Menu":
        menu_button_callback(name)
        return

    if current_set == "HUD":
        if name == "crosshair":
            if continuous_measure:
                hud.show_message("–°–ø–æ—á–∞—Ç–∫—É –∑—É–ø–∏–Ω—ñ—Ç—å –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–µ –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è")
                return
            show_crosshair = not show_crosshair
            # –°–∫–∏–¥–∞—î–º–æ —Ç–µ–∫—Å—Ç –≤—ñ–¥—Å—Ç–∞–Ω—ñ, —è–∫—â–æ –≤–∏–º–∏–∫–∞—î–º–æ –ø—Ä–∏—Ü—ñ–ª
            if show_crosshair:
                lrf_sensor.power_on()
                lrf_powered = True
                result = lrf_sensor.get_single_measurement()
                distance_text = f"Distance: {result:.1f} m" if result else "Distance: N/A"
                print("–ü—Ä–∏—Ü—ñ–ª —É–≤—ñ–º–∫–Ω–µ–Ω–æ, –¥–∞–ª–µ–∫–æ–º—ñ—Ä –∑–∞–ø—É—â–µ–Ω–æ")
            else:
                lrf_sensor.power_off()
                lrf_powered = False
                distance_text = "Distance: N/A"
                print("–ü—Ä–∏—Ü—ñ–ª –≤–∏–º–∫–Ω–µ–Ω–æ, –¥–∞–ª–µ–∫–æ–º—ñ—Ä –∑—É–ø–∏–Ω–µ–Ω–æ")
        elif name == "zoom_in":
            global zoom
            zoom = min(ZOOM_MAX, zoom + ZOOM_STEP)
        elif name == "zoom_out":
            zoom = max(ZOOM_MIN, zoom - ZOOM_STEP)
        elif name == "switch_cam":
            switch_camera()
        elif name == "single_measure":
            if continuous_measure:
                hud.show_message("–°–ø–æ—á–∞—Ç–∫—É –∑—É–ø–∏–Ω—ñ—Ç—å –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–µ –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è")
                return
            if not show_crosshair:
                hud.show_message("–°–ø–æ—á–∞—Ç–∫—É —É–≤—ñ–º–∫–Ω—ñ—Ç—å –ø—Ä–∏—Ü—ñ–ª")
                return
            do_single_measure()
        elif name == "continuous_measure":
            if not show_crosshair:
                hud.show_message("–°–ø–æ—á–∞—Ç–∫—É —É–≤—ñ–º–∫–Ω—ñ—Ç—å –ø—Ä–∏—Ü—ñ–ª")
                return
            continuous_measure = not continuous_measure
            if continuous_measure:
                continuous_start_time = time.time()
                hud.show_message("Continuous measurement ON")
            else:
                continuous_start_time = None
                hud.show_message("Continuous measurement OFF")
        elif name == "enhance":
            enhance_active = not enhance_active
        elif name == "record":
            start_or_stop_recording()
        elif name == "play":
            refresh_menu_buttons()
            set_active_button_set("Menu")
        elif name == "motion_detect":
            motion_detection_active = not motion_detection_active
            if motion_detection_active:
                motion_detector.reset() # –°–∫–∏–¥–∞—î–º–æ —Å—Ç–∞–Ω –ø—Ä–∏ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó
                hud.show_message("Motion Detection ON")
                audio_player.play()
        elif name == "exit":
            if lrf_powered:
                try:
                    audio_player.stop()
                except:
                    pass
                lrf_sensor.power_off()
            sys.exit(0)

# --- Mouse handler (–≤–∫–ª—é—á–∞—î HLS –∫–Ω–æ–ø–∫–∏) ---
def mouse_event(event, x, y, flags, param):
    global mouse_pressed_name, mouse_pressed_rect, mouse_pressed_set, video_playing
    global close_x, close_y, close_w, close_h

   # –Ø–∫—â–æ –≤—ñ–¥—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –≤—ñ–¥–µ–æ ‚Äî –∫–Ω–æ–ø–∫–∞ Close
    if video_playing and video_cap:
        if event == cv2.EVENT_LBUTTONUP:
            if close_x <= x <= close_x + close_w and close_y <= y <= close_y + close_h:
                stop_video()
        return

    # HLS –∫–Ω–æ–ø–∫–∏ (–∑–≤–µ—Ä—Ö—É)
    if current_cam_idx == 2 and hls_streams:
        for i in range(len(hls_streams)):
            bx = HLS_BTN_X_START + i * (HLS_BTN_SIZE + HLS_BTN_SPACING)
            by = HLS_BTN_Y_START
            if by <= y <= by + HLS_BTN_SIZE and bx <= x <= bx + HLS_BTN_SIZE:
                if event == cv2.EVENT_LBUTTONUP:
                    switch_hls_stream(i)
                return

    if active_set not in button_sets:
        return

    if event == cv2.EVENT_LBUTTONDOWN:
        for name, data in button_sets[active_set].items():
            if len(data) != 5:
                continue
            bx, by, bw, bh, label = data
            if bx <= x <= bx + bw and by <= y <= by + bh:
                # –ë–ª–æ–∫—É–≤–∞–Ω–Ω—è –≤—Å—ñ—Ö –∫–Ω–æ–ø–æ–∫ –∫—Ä—ñ–º switch_cam –ø—Ä–∏ HLS
                if current_cam_idx == 2 and name != "switch_cam":
                    hud.show_message("–ö–Ω–æ–ø–∫–∞ –≤–∏–º–∫–Ω–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º—ñ HLS")
                    return
                mouse_pressed_name = name
                mouse_pressed_rect = (bx, by, bw, bh)
                mouse_pressed_set = active_set
                break
        return

    if event == cv2.EVENT_LBUTTONUP:
        if mouse_pressed_name and mouse_pressed_rect:
            bx, by, bw, bh = mouse_pressed_rect
            if bx <= x <= bx + bw and by <= y <= by + bh:
                button_callback(mouse_pressed_name, True, mouse_pressed_set)
            button_pressed[mouse_pressed_name] = False
        mouse_pressed_name = None
        mouse_pressed_rect = None
        mouse_pressed_set = None

# --- –ú–∞–ª—é–≤–∞–Ω–Ω—è HLS –∫–Ω–æ–ø–æ–∫ ---
def draw_hls_buttons(frame):
    if current_cam_idx != 2 or not hls_streams:
        return frame
    for i, stream in enumerate(hls_streams):
        x = HLS_BTN_X_START + i * (HLS_BTN_SIZE + HLS_BTN_SPACING)
        y = HLS_BTN_Y_START
        color = (0, 200, 0) if i == current_hls_idx else (100, 100, 100)
        cv2.rectangle(frame, (x, y), (x + HLS_BTN_SIZE, y + HLS_BTN_SIZE), color, -1)
        # –Ω—É–º–µ—Ä–∞—Ü—ñ—è –∑ 1
        cv2.putText(frame, str(i+1), (x + 12, y + 28), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
    # –ø–æ–∫–∞–∑–∞—Ç–∏ –Ω–∞–∑–≤—É –ø–æ—Ç–æ–∫—É
    name = hls_streams[current_hls_idx]["name"]
    cv2.putText(frame, name, (HLS_BTN_X_START, HLS_BTN_Y_START + HLS_BTN_SIZE + 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)    
    return draw_text_pil(frame, name, (HLS_BTN_X_START, HLS_BTN_Y_START + HLS_BTN_SIZE + 5), FONT_HLS)


# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–∫–Ω–∞ —Ç–∞ –∫–æ–ª–±–µ–∫ –º–∏—à—ñ ---
cv2.namedWindow("Camera HUD")
cv2.setWindowProperty("Camera HUD", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
cv2.setMouseCallback("Camera HUD", mouse_event)

# --- –û—Å–Ω–æ–≤–Ω–∏–π —Ü–∏–∫–ª ---
try:
    while True:
        # –í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–ø–∏—Å–∞–Ω–æ–≥–æ –≤—ñ–¥–µ–æ
        if video_playing and video_cap:
            ret, frame = video_cap.read()
            if not ret:
                stop_video()
                continue
            frame = cv2.resize(frame, (FRAME_W, FRAME_H))
            # HUD overlay —Å–µ–∫—É–Ω–¥/—Ç–∞–π–º
            fps = video_cap.get(cv2.CAP_PROP_FPS) or FPS
            frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
            total_sec = int(frames / fps) if fps > 0 else 0
            current_sec = int(video_cap.get(cv2.CAP_PROP_POS_MSEC) / 1000)
            overlay = frame.copy()
            hud_w, hud_h = 220, 80
            overlay_x, overlay_y = FRAME_W - hud_w - 10, FRAME_H - hud_h - 10
            cv2.rectangle(overlay, (overlay_x, overlay_y),
                          (overlay_x + hud_w, overlay_y + hud_h),
                          (0, 0, 0), -1)
            frame = cv2.addWeighted(overlay, 0.4, frame, 0.6, 0)
            time_text = f"{current_sec:02d}s / {total_sec:02d}s"
            cv2.putText(frame, time_text, (overlay_x + 10, overlay_y + 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
            frame = draw_text_pil(frame, time_text, (overlay_x + 10, overlay_y + 10), FONT_HUD_LARGE)
            # Close button
            close_w, close_h = 80, 25
            close_x, close_y = overlay_x + 10, overlay_y + 45
            cv2.rectangle(frame, (close_x, close_y),
                          (close_x + close_w, close_y + close_h),
                          (50,50,50), -1)
            cv2.putText(frame, "Close", (close_x + 10, close_y + 18),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)
            cv2.imshow("Camera HUD", frame)
            if cv2.waitKey(int(1000/FPS)) & 0xFF == ord('q'):
                stop_video()
            continue

        # –û—Å–Ω–æ–≤–Ω–∞ –∫–∞–º–µ—Ä–∞
        if cap is None:
            cap = open_camera(current_cam_idx)

        ret = False
        frame = None
        try:
            if cap:
                if hasattr(cap, "read"):
                    ret, frame = cap.read()
                elif hasattr(cap, "isOpened") and cap.isOpened():
                    ret, frame = cap.read()
        except Exception as e:
            print("–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è –∫–∞–¥—Ä—É:", e)
            ret = False

        if not ret or frame is None:
            try:
                if cap: cap.release()
            except Exception:
                pass

            # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏—Ö HLS —Å—Ç—Ä—ñ–º—ñ–≤
            if current_cam_idx == 2 and hls_streams:
                initial_hls_idx = current_hls_idx
                switched = False
                for i in range(len(hls_streams)):
                    next_idx = (initial_hls_idx + 1 + i) % len(hls_streams)
                    
                    print(f"‚ö†Ô∏è HLS —Å—Ç—Ä—ñ–º '{hls_streams[current_hls_idx]['name']}' –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –°–ø—Ä–æ–±–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–Ω—è –Ω–∞ '{hls_streams[next_idx]['name']}'...")
                    hud.show_message(f"Stream unavailable, trying next...")
                    
                    switch_hls_stream(next_idx) # –¶—è —Ñ—É–Ω–∫—Ü—ñ—è –æ–Ω–æ–≤–∏—Ç—å `cap`
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤—ñ–¥–∫—Ä–∏–≤—Å—è –Ω–æ–≤–∏–π —Å—Ç—Ä—ñ–º
                    if cap and hasattr(cap, "isOpened") and cap.isOpened():
                        ret, frame = cap.read()
                        if ret and frame is not None:
                            switched = True
                            break # –ó–Ω–∞–π—à–ª–∏ —Ä–æ–±–æ—á–∏–π —Å—Ç—Ä—ñ–º, –≤–∏—Ö–æ–¥–∏–º–æ –∑ —Ü–∏–∫–ª—É
                
                if not switched:
                     hud.show_message("All HLS streams failed, switching camera")
                     switch_camera()
            else:
                # –û–±—Ä–æ–±–∫–∞ –¥–ª—è —ñ–Ω—à–∏—Ö –∫–∞–º–µ—Ä (CSI/USB)
                cam_name = camera_labels[current_cam_idx]
                print(f"‚ö†Ô∏è –ö–∞–º–µ—Ä–∞ {cam_name} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
                hud.show_message(f"No stream from: {cam_name}")
                switch_camera()

            time.sleep(0.5)
            continue

        frame = cv2.resize(frame, (FRAME_W, FRAME_H))
        h, w, _ = frame.shape
        center_x, center_y = w//2, h//2

        # Zoom
        if zoom != 1.0:
            nh, nw = int(h / zoom), int(w / zoom)
            y1, y2 = center_y - nh//2, center_y + nh//2
            x1, x2 = center_x - nw//2, center_x + nw//2
            # –∑–∞—Ö–∏—â–µ–Ω—ñ –≥—Ä–∞–Ω–∏—Ü—ñ
            y1, y2 = max(0, y1), min(h, y2)
            x1, x2 = max(0, x1), min(w, x2)
            frame = frame[y1:y2, x1:x2]
            frame = cv2.resize(frame, (w, h))

        # Continuous measure
        continuous_off_msg = ""
        if continuous_measure:
            result = lrf_sensor.get_single_measurement()
            distance_text = f"Distance: {result:.1f} m" if result else "Distance: N/A"
            if continuous_start_time:
                elapsed = (time.time() - continuous_start_time) / 60.0
                if elapsed >= CONTINUOUS_AUTO_OFF_MINUTES:
                    continuous_measure = False
                    continuous_off_msg = f"‚ö†Ô∏è –ê–≤—Ç–æ –≤–∏–º–∫–Ω–µ–Ω–Ω—è —á–µ—Ä–µ–∑ {CONTINUOUS_AUTO_OFF_MINUTES} —Ö–≤"
                    print(continuous_off_msg)

        # Enhance
        if enhance_active:
            frame = enhance_image(frame)

        # Motion Detection
        frame_count += 1
        if motion_detection_active and current_cam_idx != 2 and frame_count % MOTION_DETECT_FRAME_SKIP == 0:
            frame, motion_found = motion_detector.detect(frame)
            if motion_found:
                # –û—Å—å —Ç—É—Ç –º–∏ –≤—ñ–¥—Ç–≤–æ—Ä—é—î–º–æ –∑–≤—É–∫!
                audio_player_ondetect.play()

        # Crosshair
        if show_crosshair:
            cv2.line(frame, (center_x-20, center_y), (center_x+20, center_y), (0,0,255),2)
            cv2.line(frame, (center_x, center_y-20), (center_x, center_y+20), (0,0,255),2)
            cv2.circle(frame, (center_x, center_y), 5, (0,0,255), -1)
            if distance_text != "Distance: N/A":
                distance_display = distance_text.replace("Distance: ", "")
                cv2.putText(frame, f"{distance_display}", (center_x + 25, center_y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)

        # HUD overlay
        overlay = frame.copy()
        rect_w, rect_h = 300, 280
        rect_x, rect_y = w - rect_w - 10, 10
        cv2.rectangle(overlay, (rect_x, rect_y), (rect_x+rect_w, rect_y+rect_h), (50,50,50), -1)
        frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0)

        # HUD Text
        line_y = rect_y + 30
        if current_cam_idx == 2:
           # cv2.putText(frame, "Streaming mode", (rect_x+10, line_y),
            #            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
            frame = draw_text_pil(frame, "–†–µ–∂–∏–º —Å—Ç—Ä—ñ–º—ñ–Ω–≥—É", (rect_x+10, line_y - 15), FONT_STREAM_MODE, (255,0,0))
            
        else:
            frame = draw_text_pil(frame, distance_text, (rect_x+10, line_y - 15), FONT_HUD_LARGE)
            if continuous_measure and int(time.time()*2) % 2 == 0:
                cv2.circle(frame, (rect_x+250, line_y-10), 8, (0,255,0), -1)
            line_y += 30
            frame = draw_text_pil(frame, f"–†–æ–∑–¥—ñ–ª—å–Ω—ñ—Å—Ç—å: {FRAME_W}x{FRAME_H}", (rect_x+10, line_y - 15), FONT_HUD)
            if zoom > 1.0:
                line_y += 30
                frame = draw_text_pil(frame, f"–ó—É–º: {zoom:.2f}x", (rect_x+10, line_y - 15), FONT_HUD)
            if recording:
                line_y += 30
                frame = draw_text_pil(frame, "–ó–ê–ü–ò–°", (rect_x+10, line_y - 15), FONT_HUD, (0,0,255))
            if continuous_off_msg:
                line_y += 30
                frame = draw_text_pil(frame, continuous_off_msg, (rect_x+10, line_y - 15), FONT_HUD, (0,200,255))

        # Draw HUD buttons
        prev_continuous_state = False
        if active_set in button_sets and not video_playing:
            for name, data in button_sets[active_set].items():
                if len(data) != 5:
                    continue
                bx, by, bw, bh, label = data
                active = button_pressed.get(name, False)

                # –ë–ª–æ–∫—É–≤–∞–Ω–Ω—è –∫–Ω–æ–ø–æ–∫ –ø—Ä–∏ HLS —Ä–µ–∂–∏–º—ñ
                if current_cam_idx == 2 and name != "switch_cam":
                    color = (80, 80, 80)
                    if mouse_pressed_name == name:
                        hud.show_message("–ö–Ω–æ–ø–∫–∞ –≤–∏–º–∫–Ω–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º—ñ HLS")

                elif (name == "crosshair" or name == "single_measure") and continuous_measure:
                    color = (80, 80, 80)
                    if mouse_pressed_name == name:
                        hud.show_message("–°–ø–æ—á–∞—Ç–∫—É –∑—É–ø–∏–Ω—ñ—Ç—å –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–µ –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è")

                elif (name == "single_measure" or name == "continuous_measure") and not show_crosshair:
                    color = (80, 80, 80)
                    if mouse_pressed_name == name:
                        hud.show_message("–°–ø–æ—á–∞—Ç–∫—É —É–≤—ñ–º–∫–Ω—ñ—Ç—å –ø—Ä–∏—Ü—ñ–ª")

                elif name == "switch_cam" and current_cam_idx == 2:
                    t = time.time() - blink_start_time
                    factor = (math.sin(t * 2 * math.pi / 1.5) + 1) / 2  # –ø–µ—Ä—ñ–æ–¥ 1.5 —Å–µ–∫
                    base_color = np.array([0, 100, 200], dtype=np.float32)
                    red_color = np.array([0, 0, 255], dtype=np.float32)
                    color = (base_color * (1 - factor) + red_color * factor).astype(int)
                    color = tuple(color.tolist())
                else:
                    is_active_state = (
                        (name == "enhance" and enhance_active) or
                        (name == "record" and recording) or
                        (name == "continuous_measure" and continuous_measure) or
                        (name == "motion_detect" and motion_detection_active)
                    )
                    color = (0, 150, 0) if (active or is_active_state) else (0, 100, 200)
                cv2.rectangle(frame, (bx, by), (bx + bw, by + bh), color, -1)
                cv2.putText(frame, label, (bx+5, by+30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        # –ú–∞–ª—é—î–º–æ HLS –∫–Ω–æ–ø–∫–∏ –∑–≤–µ—Ä—Ö—É (—è–∫—â–æ –≤ HLS —Ä–µ–∂–∏–º—ñ)
        frame = draw_hls_buttons(frame)

        # –ú–∞–ª—é—î–º–æ HUD (custom)
        frame = hud.draw(frame)

        # –ó–∞–ø–∏—Å
        if recording and video_writer:
            video_writer.write(frame)

        cv2.imshow("Camera HUD", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø–æ Ctrl+C")

# --- –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è ---
try:
    if video_writer:
        video_writer.release()
    if video_cap:
        video_cap.release()
    if cap:

        cap.release()
except Exception:
    pass

cv2.destroyAllWindows()
